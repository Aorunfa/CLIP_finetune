# model config for vit-base-32
model_hyp:
  embed_dim: 512
  # vision
  image_resolution: 224
  vision_layers: 12
  vision_width: 768
  vision_patch_size: 32
  # text
  context_length: 77
  vocab_size: 49408
  transformer_width: 512
  transformer_heads: 8
  transformer_layers: 12

# loss config
loss_hyp:
  local_loss: False
  gather_with_grad: False
  cache_labels: True
  rank: 0
  world_size: -1

# train config
train:
  csv_path: './dataset/csv/train.csv'
  img_key: 'link'
  caption_key: 'caption'

val:
  csv_path: './dataset/csv/val.csv'
  img_key: 'link'
  caption_key: 'caption'

device: 'cuda:2'
resum_path: '/dev/shm/chaofeng/ViT-B-32.pt' # '/dev/shm/chaofeng/ViT-B-32.pt'    # pretrained checkpoint path, /dev/shm/chaofeng/RN50.pt
batch_size: 64    # no less than 8
num_workers: 8
epochs: 400
warmup: 1000            # per batch
warmup_start_frac: 0.001
accumulate: 10
val_accumulate: 800 # per time to run test fn
save_dir: './record/checkpoint/clip'
metric_csv: ./record/metric_ft.csv


# optimiezer
lr: 5e-7              # 1e-5 for scratch, 1e-6 for finetune 
lr_final: 0.001

# amp
amp: False
